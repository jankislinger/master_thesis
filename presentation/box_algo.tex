Denote by $\bm{p}$ the vector of all prices and by $\varrho$ the simulated outcome (price of all sold tickets).

\textbf{Algorithm 1} (Response Surface).
\begin{enumerate}
	\item Set initial value $\bm{p}^{(0)}$ and put $k := 0$.
	\item Generate data (multiple independent observations) from distribution $(\bm{p}, \varrho)$, where the predictors $\bm{p}$ have the distribution centered at $\bm{p}^k$. Join the data with previously generated data (if any).
	\item Fit the local polynomial regression at point $\bm{p}^{(k)}$. If the estimated first-order derivatives of $\mu$ are sufficiently close to zero then continue with step 5.
	\item Update $\bm{p}^{(k+1)}$ as in gradient method using estimated derivatives, increase $k := k+1$ and repeat steps 2--4.
	\item Return value $\bm{p}^{(k)}$.
\end{enumerate}

\textbf{Algorithm 2} (Cross Entropy for Noisy Optimization).
\begin{enumerate}
	\item Set initial parameter $\bm{\psi}^{(0)}$ and counter $k := 1$.
	\item Generate data (multiple independent observations) of size $n$ from distribution $(\bm{p}, \varrho)$, where the predictors have the distribution $\bm{p} \sim f( \;\cdot\; ; \bm{\psi}^{(k-1)})$. Let $\gamma_k$ be the $(1-r)$-quantile of $\varrho_1, ..., \varrho_n$.
	\item Estimate the parameter $\bm{\psi}^{(k)}$ from the best performing observations using maximum likelihood
	\[
		\bm{\psi}^{(k)} = \underset{\psi}{\max} \sum_{\bm{p}_i \geq \gamma_k} \log ( f ( \bm{p}_i; \bm{\psi} ) ).
	\]
	\item If the distribution $f( \;\cdot\; ; \bm{\psi}^{(k)})$ is almost degenerated then continue with step 6, otherwise increase $k := k+1$ and repeat steps 2--4.
	\item Return value $\bm{p}$ such that the distribution $f( \;\cdot\; ; \bm{\psi}^{(k)})$ is almost degenerated at point $\bm{p}$.
\end{enumerate}
